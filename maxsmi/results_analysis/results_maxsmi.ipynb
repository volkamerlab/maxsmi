{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# maxsmi\n",
    "## Analysis of results\n",
    "\n",
    "This notebook serves to analyse the results of the simulations ran on the Curta cluster from the Freie Universit√§t Berlin.\n",
    "\n",
    "### Maxsmi Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "\n",
    "Determine the Maxsmi models for all three tasks:\n",
    "\n",
    "- ESOL,\n",
    "- FreeSolv,\n",
    "- Lipophilicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to this notebook\n",
    "HERE = Path(_dh[-1])\n",
    "\n",
    "path_to_output = HERE.parents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path,\n",
    "              task,):\n",
    "    \"\"\"\n",
    "    Loads the result data from the Maxsmi models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        The path to output folder.\n",
    "    task : str\n",
    "        The data with associated task, e.g. \"ESOL\", \"FreeSolv\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data: pd.Pandas\n",
    "        Pandas data frame with performance metrics (on train and test sets), such as r2 score and time.\n",
    "    \"\"\"\n",
    "    if task == \"FreeSolv\":\n",
    "        ml_model = \"CONV1D\"\n",
    "        augmentation_strategy = \"augmentation_with_duplication\"\n",
    "        augmentation_number = 70\n",
    "    elif task == \"ESOL\":\n",
    "        ml_model = \"CONV1D\"\n",
    "        augmentation_strategy = \"augmentation_with_reduced_duplication\"\n",
    "        augmentation_number = 70\n",
    "    elif task == \"Lipophilicity\":\n",
    "        ml_model = \"CONV1D\"\n",
    "        augmentation_strategy = \"augmentation_without_duplication\"\n",
    "        augmentation_number = 80\n",
    "    else:\n",
    "        None\n",
    "        \n",
    "    with open(\n",
    "        f\"{path}/output/\"\n",
    "        f\"{task}_smiles_{augmentation_strategy}_\"\n",
    "        f\"{augmentation_number}_{augmentation_strategy}_\"\n",
    "        f\"{augmentation_number}_{ml_model}/\"\n",
    "        f\"results_metrics.pkl\",\n",
    "        \"rb\",\n",
    "    ) as f:\n",
    "        data = pickle.load(f)\n",
    "        print(ml_model, augmentation_strategy, augmentation_number)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE values\n",
      "-----------\n",
      "\n",
      "FreeSolv\n",
      "CONV1D augmentation_with_duplication 70\n",
      "1.032\n",
      "\n",
      "ESOL\n",
      "CONV1D augmentation_with_reduced_duplication 70\n",
      "0.569\n",
      "\n",
      "Lipophilicity\n",
      "CONV1D augmentation_without_duplication 80\n",
      "0.593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE values\\n-----------\\n\")\n",
    "for task in [\"FreeSolv\", \"ESOL\", \"Lipophilicity\"]:\n",
    "    print(task)\n",
    "    maxsmi_model = load_data(path_to_output,\n",
    "                             task)\n",
    "    print(f\"{maxsmi_model.test[0][1]:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 values\n",
      "----------\n",
      "\n",
      "FreeSolv\n",
      "CONV1D augmentation_with_duplication 70\n",
      "0.935\n",
      "\n",
      "ESOL\n",
      "CONV1D augmentation_with_reduced_duplication 70\n",
      "0.926\n",
      "\n",
      "Lipophilicity\n",
      "CONV1D augmentation_without_duplication 80\n",
      "0.758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"R^2 values\\n----------\\n\")\n",
    "for task in [\"FreeSolv\", \"ESOL\", \"Lipophilicity\"]:\n",
    "    print(task)\n",
    "    maxsmi_model = load_data(path_to_output,\n",
    "                             task)\n",
    "    print(f\"{maxsmi_model.test[0][2]:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This values indeed correspond to the minimum value shown in the `results_tables` notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From smiles to predictions\n",
    "\n",
    "\"\"\"\n",
    "import argparse\n",
    "import logging\n",
    "import logging.handlers\n",
    "import pandas\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy\n",
    "import rdkit\n",
    "from rdkit.Chem import Draw\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maxsmi.utils.utils_data import data_retrieval, smiles_in_training, data_checker\n",
    "from maxsmi.utils.utils_smiles import (\n",
    "    validity_check,\n",
    "    smiles_to_canonical,\n",
    "    smiles_to_folder_name,\n",
    "    smiles_from_folder_name,\n",
    "    is_connected,\n",
    "    ALL_SMILES_DICT,\n",
    ")\n",
    "from maxsmi.utils.utils_encoding import char_replacement\n",
    "from maxsmi.utils.utils_prediction import (\n",
    "    retrieve_longest_smiles_from_optimal_model,\n",
    "    unlabeled_smiles_max_length,\n",
    "    character_check,\n",
    "    mixture_check,\n",
    ")\n",
    "\n",
    "from maxsmi.pytorch_utils.pytorch_models import model_type\n",
    "from maxsmi.pytorch_utils.pytorch_data import AugmentSmilesData\n",
    "from maxsmi.pytorch_utils.pytorch_evaluation import out_of_sample_prediction\n",
    "from maxsmi.utils.utils_optimal_model import retrieve_optimal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    device_name = torch.cuda.get_device_name(device)\n",
    "    logging.info(f\"CUDA available: {is_cuda} with {device_name}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    logging.info(f\"CUDA available: {is_cuda}\")\n",
    "\n",
    "time_execution_start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_nb_model_parameters(task):\n",
    "    data = data_retrieval(task)\n",
    "    print(f\"Shape of training data set before processing: {data.shape} \")\n",
    "    \n",
    "    longest_smiles = retrieve_longest_smiles_from_optimal_model(task)\n",
    "\n",
    "    # Retrieve SMILES' dictionary\n",
    "    smi_dict = ALL_SMILES_DICT\n",
    "\n",
    "    # Obtain longest of all smiles\n",
    "    max_length_smi = longest_smiles\n",
    "\n",
    "    print(f\"Longest smiles in training data set: {max_length_smi} \")\n",
    "    (\n",
    "        ml_model,\n",
    "        augmentation_strategy,\n",
    "        augmentation_number,\n",
    "    ) = retrieve_optimal_model(task)\n",
    "    (ml_model_name, ml_model) = model_type(ml_model, device, smi_dict, max_length_smi)\n",
    "    print(f\"Summary of ml model used for the prediction: {ml_model} \")\n",
    "    \n",
    "    file_path = f\"{path_to_output}/prediction_models/{task}\"\n",
    "    ml_model.load_state_dict(\n",
    "        torch.load(f\"{file_path}/model_dict.pth\", map_location=device)\n",
    "    )\n",
    "    \n",
    "    total_params = sum(\n",
    "    param.numel() for param in ml_model.parameters()\n",
    "    )\n",
    "\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data set before processing: (1128, 2) \n",
      "Longest smiles in training data set: 109 \n",
      "Summary of ml model used for the prediction: Convolutional1DNetwork(\n",
      "  (convolution): Conv1d(48, 300, kernel_size=(10,), stride=(1,))\n",
      "  (fully_connected_1): Linear(in_features=30000, out_features=100, bias=True)\n",
      "  (fully_connected_out): Linear(in_features=100, out_features=1, bias=True)\n",
      ") \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3144501"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_nb_model_parameters(\"ESOL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data set before processing: (642, 2) \n",
      "Longest smiles in training data set: 76 \n",
      "Summary of ml model used for the prediction: Convolutional1DNetwork(\n",
      "  (convolution): Conv1d(48, 300, kernel_size=(10,), stride=(1,))\n",
      "  (fully_connected_1): Linear(in_features=20100, out_features=100, bias=True)\n",
      "  (fully_connected_out): Linear(in_features=100, out_features=1, bias=True)\n",
      ") \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2154501"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_nb_model_parameters(\"FreeSolv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data set before processing: (4200, 2) \n",
      "Longest smiles in training data set: 268 \n",
      "Summary of ml model used for the prediction: Convolutional1DNetwork(\n",
      "  (convolution): Conv1d(48, 300, kernel_size=(10,), stride=(1,))\n",
      "  (fully_connected_1): Linear(in_features=77700, out_features=100, bias=True)\n",
      "  (fully_connected_out): Linear(in_features=100, out_features=1, bias=True)\n",
      ") \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7914501"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_nb_model_parameters(\"lipophilicity\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
